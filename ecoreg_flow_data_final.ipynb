{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt, seaborn as sn, mpld3\n",
    "import pandas as pd, os, glob\n",
    "sn.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECOREG\n",
    "\n",
    "## Final processing of discharge data\n",
    "\n",
    "Previous notebooks have described an initial exploration of the ECOREG flow data. Susi and Jannicke have now processed the PB and MZB datasets and have decided which sites and time periods are suitable for use in the final analysis. This notebook calculates the IHA parameters for these sites. Note the following:\n",
    "\n",
    " 1. We want to calculate IHA parameters for **1 year** and **5 years** prior to the ecological sampling. <br><br>\n",
    " \n",
    " 2. There are **21** German sites suitable for the MZB analysis and **25** German sites suitable for PB analysis. All **40** Norwegian sites are suitable for both. <br><br>\n",
    " \n",
    " 3. We want to calculate IHA parameters based on both the **absolute** flow values and on values expressed **relative** to the mean flow over 1 or 5 years. Using relative values will help to remove the effects of stream size on the statistical analysis.\n",
    "\n",
    "Most of the code here is only slightly modified from previous notebooks, so the comments here are fairly brief.\n",
    " \n",
    "### 1. Get German sites of interest\n",
    "\n",
    "The table below provides site names, codes and sampling dates for the 25 PB and 21 MZB sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>name</th>\n",
       "      <th>pb</th>\n",
       "      <th>mzb</th>\n",
       "      <th>use_mzb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107000582</td>\n",
       "      <td>altenburg</td>\n",
       "      <td>2009-09-13 15:00:00</td>\n",
       "      <td>2009-06-02</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107000628</td>\n",
       "      <td>gemuend</td>\n",
       "      <td>2009-09-14 15:00:00</td>\n",
       "      <td>2009-05-04</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107000671</td>\n",
       "      <td>kornelimuenster</td>\n",
       "      <td>2007-10-21 15:00:00</td>\n",
       "      <td>2007-05-31</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107001160</td>\n",
       "      <td>oberagger</td>\n",
       "      <td>2009-08-20 15:00:00</td>\n",
       "      <td>2009-04-07</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107001168</td>\n",
       "      <td>rebbelroth</td>\n",
       "      <td>2006-07-26 15:00:00</td>\n",
       "      <td>2006-07-14</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>107001228</td>\n",
       "      <td>lohmar</td>\n",
       "      <td>2012-08-23 15:00:00</td>\n",
       "      <td>2012-08-24</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107001230</td>\n",
       "      <td>nespen</td>\n",
       "      <td>2006-09-05 15:00:00</td>\n",
       "      <td>2006-06-12</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>107001358</td>\n",
       "      <td>broel</td>\n",
       "      <td>2006-09-05 15:00:00</td>\n",
       "      <td>2006-08-21</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>107001436</td>\n",
       "      <td>geisbach</td>\n",
       "      <td>2008-05-07 15:00:00</td>\n",
       "      <td>2008-04-01</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>107001723</td>\n",
       "      <td>morsbach</td>\n",
       "      <td>2008-07-14 15:00:00</td>\n",
       "      <td>2008-05-13</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>107001855</td>\n",
       "      <td>opladen</td>\n",
       "      <td>2006-09-05 15:00:00</td>\n",
       "      <td>2006-03-20</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>107002711</td>\n",
       "      <td>herrntrop</td>\n",
       "      <td>2007-07-23 15:00:00</td>\n",
       "      <td>2007-04-25</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>107002745</td>\n",
       "      <td>rueblinghausen</td>\n",
       "      <td>2007-10-28 16:00:00</td>\n",
       "      <td>2007-05-03</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>107002835</td>\n",
       "      <td>stephansohl</td>\n",
       "      <td>2007-10-15 15:00:00</td>\n",
       "      <td>2007-06-26</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>107002866</td>\n",
       "      <td>walkmuehle</td>\n",
       "      <td>2007-10-21 15:00:00</td>\n",
       "      <td>2007-06-28</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>107002876</td>\n",
       "      <td>hagen-haspe</td>\n",
       "      <td>2007-10-12 15:00:00</td>\n",
       "      <td>2007-07-11</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>107002905</td>\n",
       "      <td>weidenau</td>\n",
       "      <td>2009-08-10 15:00:00</td>\n",
       "      <td>2009-04-27</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>107002910</td>\n",
       "      <td>niederschelden2</td>\n",
       "      <td>2009-08-17 15:00:00</td>\n",
       "      <td>2009-09-14</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>107002947</td>\n",
       "      <td>weidenau2</td>\n",
       "      <td>2009-08-19 15:00:00</td>\n",
       "      <td>2009-04-28</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>107003034</td>\n",
       "      <td>beddelhausen</td>\n",
       "      <td>2010-08-24 15:00:00</td>\n",
       "      <td>2006-07-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>107003498</td>\n",
       "      <td>bueren</td>\n",
       "      <td>2010-09-14 15:00:00</td>\n",
       "      <td>2008-06-16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>107003512</td>\n",
       "      <td>weine</td>\n",
       "      <td>2008-08-12 15:00:00</td>\n",
       "      <td>2008-05-19</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>107003769</td>\n",
       "      <td>bredelar</td>\n",
       "      <td>2010-07-20 15:00:00</td>\n",
       "      <td>2007-04-11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>107003937</td>\n",
       "      <td>meschede</td>\n",
       "      <td>2008-09-10 15:00:00</td>\n",
       "      <td>2007-07-24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>107004601</td>\n",
       "      <td>welda</td>\n",
       "      <td>2007-09-11 15:00:00</td>\n",
       "      <td>2007-07-18</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         site             name                  pb        mzb use_mzb\n",
       "0   107000582        altenburg 2009-09-13 15:00:00 2009-06-02       x\n",
       "1   107000628          gemuend 2009-09-14 15:00:00 2009-05-04       x\n",
       "2   107000671  kornelimuenster 2007-10-21 15:00:00 2007-05-31       x\n",
       "3   107001160        oberagger 2009-08-20 15:00:00 2009-04-07       x\n",
       "4   107001168       rebbelroth 2006-07-26 15:00:00 2006-07-14       x\n",
       "5   107001228           lohmar 2012-08-23 15:00:00 2012-08-24       x\n",
       "6   107001230           nespen 2006-09-05 15:00:00 2006-06-12       x\n",
       "7   107001358            broel 2006-09-05 15:00:00 2006-08-21       x\n",
       "8   107001436         geisbach 2008-05-07 15:00:00 2008-04-01       x\n",
       "9   107001723         morsbach 2008-07-14 15:00:00 2008-05-13       x\n",
       "10  107001855          opladen 2006-09-05 15:00:00 2006-03-20       x\n",
       "11  107002711        herrntrop 2007-07-23 15:00:00 2007-04-25       x\n",
       "12  107002745   rueblinghausen 2007-10-28 16:00:00 2007-05-03       x\n",
       "13  107002835      stephansohl 2007-10-15 15:00:00 2007-06-26       x\n",
       "14  107002866       walkmuehle 2007-10-21 15:00:00 2007-06-28       x\n",
       "15  107002876      hagen-haspe 2007-10-12 15:00:00 2007-07-11       x\n",
       "16  107002905         weidenau 2009-08-10 15:00:00 2009-04-27       x\n",
       "17  107002910  niederschelden2 2009-08-17 15:00:00 2009-09-14       x\n",
       "18  107002947        weidenau2 2009-08-19 15:00:00 2009-04-28       x\n",
       "19  107003034     beddelhausen 2010-08-24 15:00:00 2006-07-17     NaN\n",
       "20  107003498           bueren 2010-09-14 15:00:00 2008-06-16     NaN\n",
       "21  107003512            weine 2008-08-12 15:00:00 2008-05-19       x\n",
       "22  107003769         bredelar 2010-07-20 15:00:00 2007-04-11     NaN\n",
       "23  107003937         meschede 2008-09-10 15:00:00 2007-07-24     NaN\n",
       "24  107004601            welda 2007-09-11 15:00:00 2007-07-18       x"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get sampling/survey times for German sites\n",
    "\n",
    "# File paths\n",
    "ger_sites_xls = (r'\\\\niva-of5\\osl-userdata$\\JES\\Documents\\James_Work\\Staff\\Susi_S\\ECOREG'\n",
    "                 r'\\Raw_Data\\Germany\\Susi_Selected_German_Sites.xlsx')\n",
    "\n",
    "ger_id_xls = (r'\\\\niva-of5\\osl-userdata$\\JES\\Documents\\James_Work\\Staff\\Susi_S\\ECOREG'\n",
    "              r'\\Raw_Data\\Germany\\sites_and_ecol.xlsx')\n",
    "\n",
    "# Read data\n",
    "ger_sites = pd.read_excel(ger_sites_xls, sheetname='summary sites')\n",
    "ger_ids = pd.read_excel(ger_id_xls, sheetname='overview')\n",
    "\n",
    "# Join\n",
    "ger_sites = pd.merge(ger_sites, ger_ids, how='left', left_on='ID_RS', right_on='ID_RS')\n",
    "\n",
    "# Get columns of interest and rename\n",
    "ger_sites = ger_sites[['ID_RS', 'Site', 'date PB', 'date MZB', 'suitable for MZB analyses']]\n",
    "ger_sites.columns = ['site', 'name', 'pb', 'mzb', 'use_mzb']\n",
    "\n",
    "ger_sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get Norwegian sites of interest\n",
    "\n",
    "The table below shows site codes, names and sampling dates for the 40 Norwegian sites. Note that in the original Excel file there are some errors in the site codes, which I've fixed in order to link the ecological data to the flows data:\n",
    "\n",
    " * The correct site code for Gryta is 6.10 (originally labelled 6.1 in the *flows* dataset) <br><br>\n",
    " \n",
    " * The correct codes for Høel and Bjoreio are 50.11 and 50.13, respectively (origianlly 5.11 and 5.13 in *ECOREG_WP1_macroinvertebrate data.xlsx*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S6.9</td>\n",
       "      <td>Maridalsvatn</td>\n",
       "      <td>2013-09-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S6.10</td>\n",
       "      <td>Gryta</td>\n",
       "      <td>2013-09-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S8.2</td>\n",
       "      <td>Bjørnegårdsvingen</td>\n",
       "      <td>2013-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S16.128</td>\n",
       "      <td>Austbygdåi</td>\n",
       "      <td>2013-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S16.132</td>\n",
       "      <td>Gjuvå</td>\n",
       "      <td>2013-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S16.155</td>\n",
       "      <td>Sønnlandsvatn</td>\n",
       "      <td>2013-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S16.1</td>\n",
       "      <td>Omnefoss</td>\n",
       "      <td>2013-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S16.193</td>\n",
       "      <td>Hørte</td>\n",
       "      <td>2013-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S16.51</td>\n",
       "      <td>Hagadrag</td>\n",
       "      <td>2013-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S19.72</td>\n",
       "      <td>Jørundland</td>\n",
       "      <td>2013-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S20.2</td>\n",
       "      <td>Austenå</td>\n",
       "      <td>2013-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S25.6</td>\n",
       "      <td>Homstølvatn</td>\n",
       "      <td>2013-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S27.15</td>\n",
       "      <td>Austrumdal</td>\n",
       "      <td>2013-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S27.16</td>\n",
       "      <td>Bjordal</td>\n",
       "      <td>2013-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S27.13</td>\n",
       "      <td>Maudal</td>\n",
       "      <td>2013-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S30.8</td>\n",
       "      <td>Øvstabøstøl</td>\n",
       "      <td>2013-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S21.21</td>\n",
       "      <td>Hoslemo</td>\n",
       "      <td>2013-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S36.31</td>\n",
       "      <td>Kvilldal</td>\n",
       "      <td>2013-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S35.2</td>\n",
       "      <td>Hauge bru</td>\n",
       "      <td>2013-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S36.32</td>\n",
       "      <td>Lauvastøl</td>\n",
       "      <td>2013-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S50.11</td>\n",
       "      <td>Høel</td>\n",
       "      <td>2013-09-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S50.13</td>\n",
       "      <td>Bjoreio</td>\n",
       "      <td>2013-09-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S12.137</td>\n",
       "      <td>Gjærdeslåtten</td>\n",
       "      <td>2013-09-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S12.207</td>\n",
       "      <td>Vinde</td>\n",
       "      <td>2013-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S12.7</td>\n",
       "      <td>Etna</td>\n",
       "      <td>2013-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S12.2</td>\n",
       "      <td>Kolbjørnshus</td>\n",
       "      <td>2013-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S12.8</td>\n",
       "      <td>Grønvold</td>\n",
       "      <td>2013-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S2.439</td>\n",
       "      <td>Kvarstadseter</td>\n",
       "      <td>2013-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S2.611</td>\n",
       "      <td>Storsjøen</td>\n",
       "      <td>2013-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S2.267</td>\n",
       "      <td>Mistra</td>\n",
       "      <td>2013-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>S2.32</td>\n",
       "      <td>Atnasjø</td>\n",
       "      <td>2013-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>S2.129</td>\n",
       "      <td>Dølplass</td>\n",
       "      <td>2013-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>S2.479</td>\n",
       "      <td>Li</td>\n",
       "      <td>2013-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>S109.21</td>\n",
       "      <td>Svoni</td>\n",
       "      <td>2013-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>S109.9</td>\n",
       "      <td>Rosefoss</td>\n",
       "      <td>2013-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>S109.2</td>\n",
       "      <td>Grensehølen</td>\n",
       "      <td>2013-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>S2.592</td>\n",
       "      <td>Fokstua</td>\n",
       "      <td>2013-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>S2.303</td>\n",
       "      <td>Dombås</td>\n",
       "      <td>2013-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>S2.434</td>\n",
       "      <td>Ofossen</td>\n",
       "      <td>2013-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>S2.268</td>\n",
       "      <td>Akslen</td>\n",
       "      <td>2013-09-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       site               name       date\n",
       "0      S6.9       Maridalsvatn 2013-09-02\n",
       "1     S6.10              Gryta 2013-09-02\n",
       "2      S8.2  Bjørnegårdsvingen 2013-09-03\n",
       "3   S16.128         Austbygdåi 2013-09-03\n",
       "4   S16.132              Gjuvå 2013-09-03\n",
       "5   S16.155      Sønnlandsvatn 2013-09-04\n",
       "6     S16.1           Omnefoss 2013-09-04\n",
       "7   S16.193              Hørte 2013-09-04\n",
       "8    S16.51           Hagadrag 2013-09-05\n",
       "9    S19.72         Jørundland 2013-09-05\n",
       "10    S20.2            Austenå 2013-09-06\n",
       "11    S25.6        Homstølvatn 2013-09-06\n",
       "12   S27.15         Austrumdal 2013-09-07\n",
       "13   S27.16            Bjordal 2013-09-07\n",
       "14   S27.13             Maudal 2013-09-07\n",
       "15    S30.8        Øvstabøstøl 2013-09-07\n",
       "16   S21.21            Hoslemo 2013-09-08\n",
       "17   S36.31           Kvilldal 2013-09-08\n",
       "18    S35.2          Hauge bru 2013-09-09\n",
       "19   S36.32          Lauvastøl 2013-09-09\n",
       "20   S50.11               Høel 2013-09-10\n",
       "21   S50.13            Bjoreio 2013-09-10\n",
       "22  S12.137      Gjærdeslåtten 2013-09-10\n",
       "23  S12.207              Vinde 2013-09-11\n",
       "24    S12.7               Etna 2013-09-11\n",
       "25    S12.2       Kolbjørnshus 2013-09-11\n",
       "26    S12.8           Grønvold 2013-09-12\n",
       "27   S2.439      Kvarstadseter 2013-09-12\n",
       "28   S2.611          Storsjøen 2013-09-13\n",
       "29   S2.267             Mistra 2013-09-13\n",
       "30    S2.32            Atnasjø 2013-09-13\n",
       "31   S2.129           Dølplass 2013-09-14\n",
       "32   S2.479                 Li 2013-09-14\n",
       "33  S109.21              Svoni 2013-09-14\n",
       "34   S109.9           Rosefoss 2013-09-14\n",
       "35   S109.2        Grensehølen 2013-09-15\n",
       "36   S2.592            Fokstua 2013-09-15\n",
       "37   S2.303             Dombås 2013-09-15\n",
       "38   S2.434            Ofossen 2013-09-16\n",
       "39   S2.268             Akslen 2013-09-16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Norway sites and sampling times\n",
    "\n",
    "# File path\n",
    "nor_sites_xls = (r'\\\\niva-of5\\osl-userdata$\\JES\\Documents\\James_Work\\Staff\\Susi_S\\ECOREG'\n",
    "                 r'\\Raw_Data\\Norway\\ECOREG_WP1_macroinvertebrate data.xlsx')\n",
    "\n",
    "# Read data\n",
    "nor_sites = pd.read_excel(nor_sites_xls, sheetname='Field data')\n",
    "\n",
    "# Get columns of interest and rename\n",
    "nor_sites = nor_sites[['site', 'Site name', 'Date']]\n",
    "nor_sites.columns = ['site', 'name', 'date']\n",
    "\n",
    "nor_sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Read flows data\n",
    "\n",
    "The code below reads the flows data for all time periods and calculates daily average discharges for each site of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function to perform parsing and resampling\n",
    "\n",
    "def read_resample_flows(file_name, \n",
    "                        site_name,\n",
    "                        skiprows=11,\n",
    "                        sep=';',\n",
    "                        decimal=',',\n",
    "                        index_col=False,\n",
    "                        dt_format='%d.%m.%Y %H:%M:%S',\n",
    "                        freq='M'):\n",
    "    \"\"\" Reads flows data and resamples to the specified frequency.\n",
    "    \n",
    "    Args:\n",
    "        file_name  File to parse\n",
    "        site_name  Name of site\n",
    "        skiprows   Number of rows to skip at start\n",
    "        sep        Column separator\n",
    "        decimal    Decimal separator\n",
    "        dt_format  String specifying date format\n",
    "        freq       Resampling frequency. 'D'=daily; 'M'=monthly; 'A'=Annual\n",
    "    \n",
    "    Returns:\n",
    "        Data frame.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_name, \n",
    "                     skiprows=skiprows,\n",
    "                     header=None,\n",
    "                     names=['Date_Time', 'Q_m3/s'],\n",
    "                     index_col=False,\n",
    "                     sep=sep,\n",
    "                     decimal=decimal) \n",
    "    \n",
    "    # Parse dates\n",
    "    df.index = pd.to_datetime(df['Date_Time'], format=dt_format)\n",
    "    del df['Date_Time']\n",
    "    \n",
    "    # Resample\n",
    "    df = df.resample(freq).mean()\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    # Add site name as extra column\n",
    "    df['Site'] = site_name\n",
    "    df = df[['Site', 'Date_Time', 'Q_m3/s']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. German time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Site</th>\n",
       "      <th>altenburg</th>\n",
       "      <th>beddelhausen</th>\n",
       "      <th>bredelar</th>\n",
       "      <th>broel</th>\n",
       "      <th>bueren</th>\n",
       "      <th>geisbach</th>\n",
       "      <th>gemuend</th>\n",
       "      <th>hagen-haspe</th>\n",
       "      <th>herrntrop</th>\n",
       "      <th>kornelimuenster</th>\n",
       "      <th>...</th>\n",
       "      <th>oberagger</th>\n",
       "      <th>opladen</th>\n",
       "      <th>rebbelroth</th>\n",
       "      <th>rueblinghausen</th>\n",
       "      <th>stephansohl</th>\n",
       "      <th>walkmuehle</th>\n",
       "      <th>weidenau</th>\n",
       "      <th>weidenau2</th>\n",
       "      <th>weine</th>\n",
       "      <th>welda</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-11-01</th>\n",
       "      <td>26.871875</td>\n",
       "      <td>18.268708</td>\n",
       "      <td>1.877594</td>\n",
       "      <td>3.672760</td>\n",
       "      <td>0.969760</td>\n",
       "      <td>0.415208</td>\n",
       "      <td>4.621177</td>\n",
       "      <td>2.431885</td>\n",
       "      <td>1.921260</td>\n",
       "      <td>0.415573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290875</td>\n",
       "      <td>18.727771</td>\n",
       "      <td>1.718737</td>\n",
       "      <td>2.086000</td>\n",
       "      <td>1.908448</td>\n",
       "      <td>0.494516</td>\n",
       "      <td>3.243656</td>\n",
       "      <td>3.235000</td>\n",
       "      <td>1.692729</td>\n",
       "      <td>3.491375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-02</th>\n",
       "      <td>23.022760</td>\n",
       "      <td>16.494115</td>\n",
       "      <td>2.390760</td>\n",
       "      <td>9.018885</td>\n",
       "      <td>1.489625</td>\n",
       "      <td>2.006896</td>\n",
       "      <td>11.703562</td>\n",
       "      <td>6.462062</td>\n",
       "      <td>2.376573</td>\n",
       "      <td>0.934281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891073</td>\n",
       "      <td>31.387135</td>\n",
       "      <td>6.230521</td>\n",
       "      <td>5.112292</td>\n",
       "      <td>4.790135</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>5.062771</td>\n",
       "      <td>7.806500</td>\n",
       "      <td>2.939740</td>\n",
       "      <td>4.934354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-03</th>\n",
       "      <td>25.203240</td>\n",
       "      <td>28.141208</td>\n",
       "      <td>2.688115</td>\n",
       "      <td>14.343844</td>\n",
       "      <td>1.991990</td>\n",
       "      <td>2.754521</td>\n",
       "      <td>16.447729</td>\n",
       "      <td>6.961010</td>\n",
       "      <td>2.508802</td>\n",
       "      <td>2.005365</td>\n",
       "      <td>...</td>\n",
       "      <td>1.120167</td>\n",
       "      <td>33.298771</td>\n",
       "      <td>7.345625</td>\n",
       "      <td>6.892604</td>\n",
       "      <td>5.405156</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>6.586396</td>\n",
       "      <td>9.629219</td>\n",
       "      <td>3.665646</td>\n",
       "      <td>6.419531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-04</th>\n",
       "      <td>24.294562</td>\n",
       "      <td>31.574656</td>\n",
       "      <td>3.038625</td>\n",
       "      <td>14.155792</td>\n",
       "      <td>2.095510</td>\n",
       "      <td>1.763750</td>\n",
       "      <td>13.846292</td>\n",
       "      <td>6.824437</td>\n",
       "      <td>2.881615</td>\n",
       "      <td>1.529271</td>\n",
       "      <td>...</td>\n",
       "      <td>1.021458</td>\n",
       "      <td>30.684490</td>\n",
       "      <td>6.595417</td>\n",
       "      <td>7.198438</td>\n",
       "      <td>5.168510</td>\n",
       "      <td>1.040302</td>\n",
       "      <td>7.885073</td>\n",
       "      <td>9.769125</td>\n",
       "      <td>3.546250</td>\n",
       "      <td>6.536563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-05</th>\n",
       "      <td>23.682260</td>\n",
       "      <td>28.632313</td>\n",
       "      <td>3.002312</td>\n",
       "      <td>9.719073</td>\n",
       "      <td>1.887323</td>\n",
       "      <td>1.209469</td>\n",
       "      <td>11.142406</td>\n",
       "      <td>6.078385</td>\n",
       "      <td>2.869292</td>\n",
       "      <td>1.328865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676135</td>\n",
       "      <td>25.387385</td>\n",
       "      <td>4.415521</td>\n",
       "      <td>5.395000</td>\n",
       "      <td>3.741135</td>\n",
       "      <td>1.440000</td>\n",
       "      <td>6.802365</td>\n",
       "      <td>7.782625</td>\n",
       "      <td>2.976948</td>\n",
       "      <td>5.927667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Site        altenburg  beddelhausen  bredelar      broel    bueren  geisbach  \\\n",
       "Date_Time                                                                      \n",
       "2002-11-01  26.871875     18.268708  1.877594   3.672760  0.969760  0.415208   \n",
       "2002-11-02  23.022760     16.494115  2.390760   9.018885  1.489625  2.006896   \n",
       "2002-11-03  25.203240     28.141208  2.688115  14.343844  1.991990  2.754521   \n",
       "2002-11-04  24.294562     31.574656  3.038625  14.155792  2.095510  1.763750   \n",
       "2002-11-05  23.682260     28.632313  3.002312   9.719073  1.887323  1.209469   \n",
       "\n",
       "Site          gemuend  hagen-haspe  herrntrop  kornelimuenster    ...     \\\n",
       "Date_Time                                                         ...      \n",
       "2002-11-01   4.621177     2.431885   1.921260         0.415573    ...      \n",
       "2002-11-02  11.703562     6.462062   2.376573         0.934281    ...      \n",
       "2002-11-03  16.447729     6.961010   2.508802         2.005365    ...      \n",
       "2002-11-04  13.846292     6.824437   2.881615         1.529271    ...      \n",
       "2002-11-05  11.142406     6.078385   2.869292         1.328865    ...      \n",
       "\n",
       "Site        oberagger    opladen  rebbelroth  rueblinghausen  stephansohl  \\\n",
       "Date_Time                                                                   \n",
       "2002-11-01   0.290875  18.727771    1.718737        2.086000     1.908448   \n",
       "2002-11-02   0.891073  31.387135    6.230521        5.112292     4.790135   \n",
       "2002-11-03   1.120167  33.298771    7.345625        6.892604     5.405156   \n",
       "2002-11-04   1.021458  30.684490    6.595417        7.198438     5.168510   \n",
       "2002-11-05   0.676135  25.387385    4.415521        5.395000     3.741135   \n",
       "\n",
       "Site        walkmuehle  weidenau  weidenau2     weine     welda  \n",
       "Date_Time                                                        \n",
       "2002-11-01    0.494516  3.243656   3.235000  1.692729  3.491375  \n",
       "2002-11-02    0.496000  5.062771   7.806500  2.939740  4.934354  \n",
       "2002-11-03    0.499000  6.586396   9.629219  3.665646  6.419531  \n",
       "2002-11-04    1.040302  7.885073   9.769125  3.546250  6.536563  \n",
       "2002-11-05    1.440000  6.802365   7.782625  2.976948  5.927667  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse German flows (all data)\n",
    "\n",
    "###############################################################################\n",
    "# User input\n",
    "in_fold = r'\\\\niva-of5\\osl-userdata$\\JES\\Documents\\James_Work\\Staff\\Susi_S\\ECOREG\\Raw_Data\\Germany'\n",
    "\n",
    "# Frequency for resampling\n",
    "freq = 'D'\n",
    "###############################################################################\n",
    "  \n",
    "# Get list of flow files to process\n",
    "search_path = os.path.join(in_fold, 'Flows', '*')\n",
    "file_list = glob.glob(search_path)\n",
    "\n",
    "# Read files\n",
    "df_list = []\n",
    "for file_name in file_list:\n",
    "    # Get site name\n",
    "    site_name = os.path.split(file_name)[1].split('_')[0]\n",
    "    \n",
    "    # Decide whether we need to process this site\n",
    "    if site_name in ger_sites['name'].values:\n",
    "    \n",
    "        # Process differently according to file extension and file formatting\n",
    "        if site_name == 'hagen-eckesey':\n",
    "            # This site has a different date format to the other CSV files\n",
    "            df = read_resample_flows(file_name,\n",
    "                                     site_name,\n",
    "                                     skiprows=11,\n",
    "                                     sep=';',\n",
    "                                     decimal='.',\n",
    "                                     dt_format='%d.%m.%Y %H:%M',\n",
    "                                     freq=freq)        \n",
    "            df_list.append(df)\n",
    "\n",
    "        elif file_name[-3:] == 'csv':\n",
    "            # The rest of the CSV files are consistent\n",
    "            df = read_resample_flows(file_name,\n",
    "                                     site_name,\n",
    "                                     skiprows=11,\n",
    "                                     sep=';',\n",
    "                                     decimal=',',\n",
    "                                     dt_format='%d.%m.%Y %H:%M:%S',\n",
    "                                     freq=freq)        \n",
    "            df_list.append(df)\n",
    "\n",
    "        elif file_name[-3:] == 'zrx':\n",
    "            # The ZRX files are also consistent\n",
    "            df = read_resample_flows(file_name,\n",
    "                                     site_name,\n",
    "                                     skiprows=5,\n",
    "                                     sep=' ',\n",
    "                                     decimal='.',\n",
    "                                     dt_format='%Y%m%d%H%M%S',\n",
    "                                     freq=freq)        \n",
    "            df_list.append(df)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Unexpected file types found in flows data folder.')\n",
    "\n",
    "# Concatenate results\n",
    "ger_df = pd.concat(df_list, axis=0)\n",
    "\n",
    "# Pivot\n",
    "ger_df = ger_df.pivot(index='Date_Time', columns='Site', values='Q_m3/s')\n",
    "\n",
    "ger_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Norwegian time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S109.2</th>\n",
       "      <th>S109.21</th>\n",
       "      <th>S109.9</th>\n",
       "      <th>S12.137</th>\n",
       "      <th>S12.2</th>\n",
       "      <th>S12.207</th>\n",
       "      <th>S12.7</th>\n",
       "      <th>S12.8</th>\n",
       "      <th>S16.1</th>\n",
       "      <th>S16.128</th>\n",
       "      <th>...</th>\n",
       "      <th>S27.16</th>\n",
       "      <th>S30.8</th>\n",
       "      <th>S35.2</th>\n",
       "      <th>S36.31</th>\n",
       "      <th>S36.32</th>\n",
       "      <th>S50.11</th>\n",
       "      <th>S50.13</th>\n",
       "      <th>S6.10</th>\n",
       "      <th>S6.9</th>\n",
       "      <th>S8.2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>9.47282</td>\n",
       "      <td>0.51892</td>\n",
       "      <td>3.59022</td>\n",
       "      <td>20.14581</td>\n",
       "      <td>6.63797</td>\n",
       "      <td>0.92749</td>\n",
       "      <td>1.96617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.23073</td>\n",
       "      <td>1.37648</td>\n",
       "      <td>...</td>\n",
       "      <td>5.29065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.19093</td>\n",
       "      <td>0.97375</td>\n",
       "      <td>1.29150</td>\n",
       "      <td>0.09012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.27335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>7.72643</td>\n",
       "      <td>0.51720</td>\n",
       "      <td>2.67732</td>\n",
       "      <td>19.96283</td>\n",
       "      <td>6.63797</td>\n",
       "      <td>0.95418</td>\n",
       "      <td>1.60709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.96029</td>\n",
       "      <td>1.26817</td>\n",
       "      <td>...</td>\n",
       "      <td>10.30134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.22380</td>\n",
       "      <td>1.00387</td>\n",
       "      <td>1.26581</td>\n",
       "      <td>0.09012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.95569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>5.95121</td>\n",
       "      <td>0.50668</td>\n",
       "      <td>2.28116</td>\n",
       "      <td>19.98467</td>\n",
       "      <td>6.63797</td>\n",
       "      <td>0.90896</td>\n",
       "      <td>1.52404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.14732</td>\n",
       "      <td>1.18040</td>\n",
       "      <td>...</td>\n",
       "      <td>12.24407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.28290</td>\n",
       "      <td>1.12578</td>\n",
       "      <td>1.24016</td>\n",
       "      <td>0.09866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.73315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>5.95121</td>\n",
       "      <td>0.49346</td>\n",
       "      <td>2.07084</td>\n",
       "      <td>20.27129</td>\n",
       "      <td>6.25267</td>\n",
       "      <td>0.76776</td>\n",
       "      <td>1.51251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.49061</td>\n",
       "      <td>1.13079</td>\n",
       "      <td>...</td>\n",
       "      <td>10.02236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.28754</td>\n",
       "      <td>1.16399</td>\n",
       "      <td>1.21454</td>\n",
       "      <td>0.09866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.75367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>5.95121</td>\n",
       "      <td>0.50905</td>\n",
       "      <td>2.08630</td>\n",
       "      <td>19.97185</td>\n",
       "      <td>6.25267</td>\n",
       "      <td>0.87590</td>\n",
       "      <td>1.46788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.34705</td>\n",
       "      <td>0.98371</td>\n",
       "      <td>...</td>\n",
       "      <td>6.99554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.43283</td>\n",
       "      <td>1.14173</td>\n",
       "      <td>1.21454</td>\n",
       "      <td>0.09457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.55473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             S109.2  S109.21   S109.9   S12.137    S12.2  S12.207    S12.7  \\\n",
       "Date                                                                         \n",
       "2000-01-01  9.47282  0.51892  3.59022  20.14581  6.63797  0.92749  1.96617   \n",
       "2000-01-02  7.72643  0.51720  2.67732  19.96283  6.63797  0.95418  1.60709   \n",
       "2000-01-03  5.95121  0.50668  2.28116  19.98467  6.63797  0.90896  1.52404   \n",
       "2000-01-04  5.95121  0.49346  2.07084  20.27129  6.25267  0.76776  1.51251   \n",
       "2000-01-05  5.95121  0.50905  2.08630  19.97185  6.25267  0.87590  1.46788   \n",
       "\n",
       "            S12.8     S16.1  S16.128   ...       S27.16  S30.8  S35.2  S36.31  \\\n",
       "Date                                   ...                                      \n",
       "2000-01-01    NaN  17.23073  1.37648   ...      5.29065    NaN    NaN     NaN   \n",
       "2000-01-02    NaN  16.96029  1.26817   ...     10.30134    NaN    NaN     NaN   \n",
       "2000-01-03    NaN  18.14732  1.18040   ...     12.24407    NaN    NaN     NaN   \n",
       "2000-01-04    NaN  19.49061  1.13079   ...     10.02236    NaN    NaN     NaN   \n",
       "2000-01-05    NaN  21.34705  0.98371   ...      6.99554    NaN    NaN     NaN   \n",
       "\n",
       "             S36.32   S50.11   S50.13    S6.10  S6.9     S8.2  \n",
       "Date                                                           \n",
       "2000-01-01  0.19093  0.97375  1.29150  0.09012   NaN  2.27335  \n",
       "2000-01-02  0.22380  1.00387  1.26581  0.09012   NaN  1.95569  \n",
       "2000-01-03  0.28290  1.12578  1.24016  0.09866   NaN  1.73315  \n",
       "2000-01-04  0.28754  1.16399  1.21454  0.09866   NaN  1.75367  \n",
       "2000-01-05  0.43283  1.14173  1.21454  0.09457   NaN  1.55473  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse Norwegian flows (all data)\n",
    "nor_xls = r'\\\\niva-of5\\osl-userdata$\\JES\\Documents\\James_Work\\Staff\\Susi_S\\ECOREG\\Raw_Data\\Norway\\ECOREG discharge complete.xlsx'\n",
    "nor_df = pd.read_excel(nor_xls, \n",
    "                       sheetname='discharge ECOREG',\n",
    "                       index_col=0)\n",
    "\n",
    "# Resample to daily\n",
    "nor_df = nor_df.resample('D').mean()\n",
    "\n",
    "# Interpolate\n",
    "nor_df['S12.8'].interpolate(method='linear', inplace=True)\n",
    "\n",
    "nor_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate IHA parameters\n",
    "\n",
    "#### 4.1. Generate lookup table between site codes and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S6.9</th>\n",
       "      <td>Maridalsvatn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S6.10</th>\n",
       "      <td>Gryta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S8.2</th>\n",
       "      <td>Bjørnegårdsvingen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S16.128</th>\n",
       "      <td>Austbygdåi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S16.132</th>\n",
       "      <td>Gjuvå</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S16.155</th>\n",
       "      <td>Sønnlandsvatn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S16.1</th>\n",
       "      <td>Omnefoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S16.193</th>\n",
       "      <td>Hørte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S16.51</th>\n",
       "      <td>Hagadrag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S19.72</th>\n",
       "      <td>Jørundland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S20.2</th>\n",
       "      <td>Austenå</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S25.6</th>\n",
       "      <td>Homstølvatn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S27.15</th>\n",
       "      <td>Austrumdal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S27.16</th>\n",
       "      <td>Bjordal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S27.13</th>\n",
       "      <td>Maudal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S30.8</th>\n",
       "      <td>Øvstabøstøl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S21.21</th>\n",
       "      <td>Hoslemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S36.31</th>\n",
       "      <td>Kvilldal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S35.2</th>\n",
       "      <td>Hauge bru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S36.32</th>\n",
       "      <td>Lauvastøl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S50.11</th>\n",
       "      <td>Høel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S50.13</th>\n",
       "      <td>Bjoreio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S12.137</th>\n",
       "      <td>Gjærdeslåtten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S12.207</th>\n",
       "      <td>Vinde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S12.7</th>\n",
       "      <td>Etna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S12.2</th>\n",
       "      <td>Kolbjørnshus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S12.8</th>\n",
       "      <td>Grønvold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2.439</th>\n",
       "      <td>Kvarstadseter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2.611</th>\n",
       "      <td>Storsjøen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2.267</th>\n",
       "      <td>Mistra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S109.2</th>\n",
       "      <td>Grensehølen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2.592</th>\n",
       "      <td>Fokstua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2.303</th>\n",
       "      <td>Dombås</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2.434</th>\n",
       "      <td>Ofossen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2.268</th>\n",
       "      <td>Akslen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107000582</th>\n",
       "      <td>altenburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107000628</th>\n",
       "      <td>gemuend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107000671</th>\n",
       "      <td>kornelimuenster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107001160</th>\n",
       "      <td>oberagger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107001168</th>\n",
       "      <td>rebbelroth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107001228</th>\n",
       "      <td>lohmar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107001230</th>\n",
       "      <td>nespen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107001358</th>\n",
       "      <td>broel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107001436</th>\n",
       "      <td>geisbach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107001723</th>\n",
       "      <td>morsbach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107001855</th>\n",
       "      <td>opladen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107002711</th>\n",
       "      <td>herrntrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107002745</th>\n",
       "      <td>rueblinghausen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107002835</th>\n",
       "      <td>stephansohl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107002866</th>\n",
       "      <td>walkmuehle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107002876</th>\n",
       "      <td>hagen-haspe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107002905</th>\n",
       "      <td>weidenau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107002910</th>\n",
       "      <td>niederschelden2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107002947</th>\n",
       "      <td>weidenau2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107003034</th>\n",
       "      <td>beddelhausen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107003498</th>\n",
       "      <td>bueren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107003512</th>\n",
       "      <td>weine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107003769</th>\n",
       "      <td>bredelar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107003937</th>\n",
       "      <td>meschede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107004601</th>\n",
       "      <td>welda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name\n",
       "site                        \n",
       "S6.9            Maridalsvatn\n",
       "S6.10                  Gryta\n",
       "S8.2       Bjørnegårdsvingen\n",
       "S16.128           Austbygdåi\n",
       "S16.132                Gjuvå\n",
       "S16.155        Sønnlandsvatn\n",
       "S16.1               Omnefoss\n",
       "S16.193                Hørte\n",
       "S16.51              Hagadrag\n",
       "S19.72            Jørundland\n",
       "S20.2                Austenå\n",
       "S25.6            Homstølvatn\n",
       "S27.15            Austrumdal\n",
       "S27.16               Bjordal\n",
       "S27.13                Maudal\n",
       "S30.8            Øvstabøstøl\n",
       "S21.21               Hoslemo\n",
       "S36.31              Kvilldal\n",
       "S35.2              Hauge bru\n",
       "S36.32             Lauvastøl\n",
       "S50.11                  Høel\n",
       "S50.13               Bjoreio\n",
       "S12.137        Gjærdeslåtten\n",
       "S12.207                Vinde\n",
       "S12.7                   Etna\n",
       "S12.2           Kolbjørnshus\n",
       "S12.8               Grønvold\n",
       "S2.439         Kvarstadseter\n",
       "S2.611             Storsjøen\n",
       "S2.267                Mistra\n",
       "...                      ...\n",
       "S109.2           Grensehølen\n",
       "S2.592               Fokstua\n",
       "S2.303                Dombås\n",
       "S2.434               Ofossen\n",
       "S2.268                Akslen\n",
       "107000582          altenburg\n",
       "107000628            gemuend\n",
       "107000671    kornelimuenster\n",
       "107001160          oberagger\n",
       "107001168         rebbelroth\n",
       "107001228             lohmar\n",
       "107001230             nespen\n",
       "107001358              broel\n",
       "107001436           geisbach\n",
       "107001723           morsbach\n",
       "107001855            opladen\n",
       "107002711          herrntrop\n",
       "107002745     rueblinghausen\n",
       "107002835        stephansohl\n",
       "107002866         walkmuehle\n",
       "107002876        hagen-haspe\n",
       "107002905           weidenau\n",
       "107002910    niederschelden2\n",
       "107002947          weidenau2\n",
       "107003034       beddelhausen\n",
       "107003498             bueren\n",
       "107003512              weine\n",
       "107003769           bredelar\n",
       "107003937           meschede\n",
       "107004601              welda\n",
       "\n",
       "[65 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract codes and names\n",
    "ger_codes = ger_sites[['site', 'name']]\n",
    "nor_codes = nor_sites[['site', 'name']]\n",
    "\n",
    "# Concatenate\n",
    "codes = pd.concat([nor_codes, ger_codes], axis=0)\n",
    "codes.index = codes['site']\n",
    "del codes['site']\n",
    "\n",
    "codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Function to pass time series to IHA pachage in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_iha(df):\n",
    "    \"\"\" Processes the first five groups of IHA indicators.\n",
    "    \n",
    "    Args:\n",
    "        df  Pandas data frame with DAILY resolution consisting\n",
    "            of a single column entitled 'site_name' and a date-time\n",
    "            index.\n",
    "    \n",
    "    Returns:\n",
    "        Pandas data frame of IHA parameters calculated from the\n",
    "        IHA R package.\n",
    "    \"\"\"\n",
    "    # Set up connection to R. This all seems unnecessarily complicated!\n",
    "    import rpy2.interactive as r\n",
    "    import rpy2.interactive.packages\n",
    "    from rpy2.robjects.packages import importr\n",
    "    import pandas.rpy.common as com\n",
    "    from rpy2.robjects import pandas2ri\n",
    "    pandas2ri.activate()\n",
    "    \n",
    "    # Circular mean function from scipy (see above)\n",
    "    from scipy.stats import circmean\n",
    "\n",
    "    # Load necessary R packages\n",
    "    importr('zoo', lib_loc=\"//niva-of5/osl-userdata$/JES/Documents/R/win-library/3.2\")   \n",
    "    importr('IHA', lib_loc=\"//niva-of5/osl-userdata$/JES/Documents/R/win-library/3.2\")\n",
    "    \n",
    "    # Import R packages into interactive session\n",
    "    zoo = r.packages.importr('zoo')\n",
    "    iha = r.packages.importr('IHA')\n",
    "    \n",
    "    # Get path to package methods\n",
    "    rlib = r.packages.packages\n",
    "\n",
    "    # Convert df to 2 columns ['Dates', 'Flows']\n",
    "    df2 = df.reset_index()\n",
    "\n",
    "    # Convert Pandas df to R \n",
    "    ts = rlib.zoo.read_zoo(df2, format=\"%Y-%m-%d\")\n",
    "    \n",
    "    # Processing for Group 1\n",
    "    # Calculate group 1 stats.\n",
    "    rg1 = rlib.IHA.group1(ts)\n",
    "\n",
    "    # Convert back to Python\n",
    "    grp1 = com.convert_robj(rg1)\n",
    "\n",
    "    # Get stats\n",
    "    grp1 = grp1.describe().T\n",
    "\n",
    "    # Coefficient of dispersion\n",
    "    grp1['CoD'] = (grp1['75%'] - grp1['25%']) / grp1['50%']\n",
    "\n",
    "    # Format grp 1 df\n",
    "    grp1.index.name = 'Indicator'\n",
    "    grp1.reset_index(inplace=True)\n",
    "    grp1['Group'] = 1\n",
    "    grp1.index = [grp1['Group'], grp1['Indicator']]\n",
    "    grp1 = grp1[['50%', 'CoD']]\n",
    "    \n",
    "    # Processing for Group 2\n",
    "    # Calculate group 2 stats.\n",
    "    rg2 = rlib.IHA.group2(ts)\n",
    "\n",
    "    # Convert back to Python\n",
    "    grp2 = com.convert_robj(rg2)\n",
    "\n",
    "    # Get stats\n",
    "    grp2 = grp2.describe().T\n",
    "\n",
    "    # Coefficient of dispersion\n",
    "    grp2['CoD'] = (grp2['75%'] - grp2['25%']) / grp2['50%']\n",
    "\n",
    "    # Format grp 2 df\n",
    "    grp2.index.name = 'Indicator'\n",
    "    grp2.reset_index(inplace=True)\n",
    "    grp2['Group'] = 2\n",
    "    grp2 = grp2[grp2['Indicator'] != 'year']\n",
    "    grp2.index = [grp2['Group'], grp2['Indicator']]\n",
    "    grp2 = grp2[['50%', 'CoD']]\n",
    "\n",
    "    # Processing for Group 3\n",
    "    # Calculate group 3 stats.\n",
    "    rg3 = rlib.IHA.group3(ts)\n",
    "\n",
    "    # Convert back to Python\n",
    "    grp3 = com.convert_robj(rg3)\n",
    "\n",
    "    # Get stats using circular mean and assuming 366 days per year (as in IHA)\n",
    "    c_av = circmean(grp3, high=366, low=0, axis=0)\n",
    "    \n",
    "    # We won't include a CoD for this stat.\n",
    "    # Build df to store this info\n",
    "    grp3 = pd.DataFrame(data=[c_av, [pd.np.nan, pd.np.nan]], \n",
    "                        columns=['Min', 'Max'],\n",
    "                        index=['50%', 'CoD']).T\n",
    "\n",
    "    # Format grp 2 df\n",
    "    grp3.index.name = 'Indicator'\n",
    "    grp3.reset_index(inplace=True)\n",
    "    grp3['Group'] = 3\n",
    "    grp3.index = [grp3['Group'], grp3['Indicator']]\n",
    "    grp3 = grp3[['50%', 'CoD']]\n",
    "\n",
    "    # Processing for Group 4\n",
    "    # Calculate group 4 stats.\n",
    "    rg4 = rlib.IHA.group4(ts)\n",
    "\n",
    "    # Convert back to Python\n",
    "    grp4 = com.convert_robj(rg4)\n",
    "\n",
    "    # Get stats\n",
    "    grp4 = grp4.describe().T\n",
    "\n",
    "    # Coefficient of dispersion\n",
    "    grp4['CoD'] = (grp4['75%'] - grp4['25%']) / grp4['50%']\n",
    "\n",
    "    # Format grp 4 df\n",
    "    grp4.index.name = 'Indicator'\n",
    "    grp4.reset_index(inplace=True)\n",
    "    grp4['Group'] = 4\n",
    "    grp4.index = [grp4['Group'], grp4['Indicator']]\n",
    "    grp4 = grp4[['50%', 'CoD']]  \n",
    "\n",
    "    # Processing for Group 5\n",
    "    # Calculate group 5 stats.\n",
    "    rg5 = rlib.IHA.group5(ts)\n",
    "\n",
    "    # Convert back to Python\n",
    "    grp5 = com.convert_robj(rg5)\n",
    "\n",
    "    # Get stats\n",
    "    grp5 = grp5.describe().T\n",
    "\n",
    "    # Coefficient of dispersion\n",
    "    grp5['CoD'] = (grp5['75%'] - grp5['25%']) / grp5['50%']\n",
    "\n",
    "    # Format grp 4 df\n",
    "    grp5.index.name = 'Indicator'\n",
    "    grp5.reset_index(inplace=True)\n",
    "    grp5['Group'] = 5\n",
    "    grp5.index = [grp5['Group'], grp5['Indicator']]\n",
    "    grp5 = grp5[['50%', 'CoD']]  \n",
    "\n",
    "    # Combine results\n",
    "    iha_res = pd.concat([grp1, grp2, grp3, grp4, grp5], axis=0)\n",
    "    \n",
    "    # Rename 50% col (because not all values are actually medians)\n",
    "    # Also add heirarchical index for site_name\n",
    "    iha_res.columns = [[df.columns[0], df.columns[0]],['Cent_Est', 'CoD']]\n",
    "   \n",
    "    return iha_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Loop over sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing short term abs values for pb...\n",
      "  Norway:\n",
      "    S109.2.\n",
      "    S109.21.\n",
      "    S109.9.\n",
      "    S12.137.\n",
      "    S12.2.\n",
      "    S12.207.\n",
      "    S12.7.\n",
      "    S12.8.\n",
      "    S16.1.\n",
      "    S16.128.\n",
      "    S16.132.\n",
      "    S16.155.\n",
      "    S16.193.\n",
      "    S16.51.\n",
      "    S19.72.\n",
      "    S2.129.\n",
      "    S2.267.\n",
      "    S2.268.\n",
      "    S2.303.\n",
      "    S2.32.\n",
      "    S2.434.\n",
      "    S2.439.\n",
      "    S2.479.\n",
      "    S2.592.\n",
      "    S2.611.\n",
      "    S20.2.\n",
      "    S21.21.\n",
      "    S25.6.\n",
      "    S27.13.\n",
      "    S27.15.\n",
      "    S27.16.\n",
      "    S30.8.\n",
      "    S35.2.\n",
      "    S36.31.\n",
      "    S36.32.\n",
      "    S50.11.\n",
      "    S50.13.\n",
      "    S6.10.\n",
      "    S6.9.\n",
      "    S8.2.\n",
      "  Germany:\n",
      "    altenburg.\n",
      "    beddelhausen.\n",
      "    bredelar.\n",
      "    broel.\n",
      "    bueren.\n",
      "    geisbach.\n",
      "    gemuend.\n",
      "    hagen-haspe.\n",
      "    herrntrop.\n",
      "    kornelimuenster.\n",
      "    lohmar.\n",
      "    meschede.\n",
      "    morsbach.\n",
      "    nespen.\n",
      "    niederschelden2.\n",
      "    oberagger.\n",
      "    opladen.\n",
      "    rebbelroth.\n",
      "    rueblinghausen.\n",
      "    stephansohl.\n",
      "    walkmuehle.\n",
      "    weidenau.\n",
      "    weidenau2.\n",
      "    weine.\n",
      "    welda.\n",
      "Processing short term abs values for mzb...\n",
      "  Norway:\n",
      "    S109.2.\n",
      "    S109.21.\n",
      "    S109.9.\n",
      "    S12.137.\n",
      "    S12.2.\n",
      "    S12.207.\n",
      "    S12.7.\n",
      "    S12.8.\n",
      "    S16.1.\n",
      "    S16.128.\n",
      "    S16.132.\n",
      "    S16.155.\n",
      "    S16.193.\n",
      "    S16.51.\n",
      "    S19.72.\n",
      "    S2.129.\n",
      "    S2.267.\n",
      "    S2.268.\n",
      "    S2.303.\n",
      "    S2.32.\n",
      "    S2.434.\n",
      "    S2.439.\n",
      "    S2.479.\n",
      "    S2.592.\n",
      "    S2.611.\n",
      "    S20.2.\n",
      "    S21.21.\n",
      "    S25.6.\n",
      "    S27.13.\n",
      "    S27.15.\n",
      "    S27.16.\n",
      "    S30.8.\n",
      "    S35.2.\n",
      "    S36.31.\n",
      "    S36.32.\n",
      "    S50.11.\n",
      "    S50.13.\n",
      "    S6.10.\n",
      "    S6.9.\n",
      "    S8.2.\n",
      "  Germany:\n",
      "    altenburg.\n",
      "    beddelhausen.\n",
      "    bredelar.\n",
      "    broel.\n",
      "    bueren.\n",
      "    geisbach.\n",
      "    gemuend.\n",
      "    hagen-haspe.\n",
      "    herrntrop.\n",
      "    kornelimuenster.\n",
      "    lohmar.\n",
      "    meschede.\n",
      "    morsbach.\n",
      "    nespen.\n",
      "    niederschelden2.\n",
      "    oberagger.\n",
      "    opladen.\n",
      "    rebbelroth.\n",
      "    rueblinghausen.\n",
      "    stephansohl.\n",
      "    walkmuehle.\n",
      "    weidenau.\n",
      "    weidenau2.\n",
      "    weine.\n",
      "    welda.\n",
      "Processing short term rel values for pb...\n",
      "  Norway:\n",
      "    S109.2.\n",
      "    S109.21.\n",
      "    S109.9.\n",
      "    S12.137.\n",
      "    S12.2.\n",
      "    S12.207.\n",
      "    S12.7.\n",
      "    S12.8.\n",
      "    S16.1.\n",
      "    S16.128.\n",
      "    S16.132.\n",
      "    S16.155.\n",
      "    S16.193.\n",
      "    S16.51.\n",
      "    S19.72.\n",
      "    S2.129.\n",
      "    S2.267.\n",
      "    S2.268.\n",
      "    S2.303.\n",
      "    S2.32.\n",
      "    S2.434.\n",
      "    S2.439.\n",
      "    S2.479.\n",
      "    S2.592.\n",
      "    S2.611.\n",
      "    S20.2.\n",
      "    S21.21.\n",
      "    S25.6.\n",
      "    S27.13.\n",
      "    S27.15.\n",
      "    S27.16.\n",
      "    S30.8.\n",
      "    S35.2.\n",
      "    S36.31.\n",
      "    S36.32.\n",
      "    S50.11.\n",
      "    S50.13.\n",
      "    S6.10.\n",
      "    S6.9.\n",
      "    S8.2.\n",
      "  Germany:\n",
      "    altenburg.\n",
      "    beddelhausen.\n",
      "    bredelar.\n",
      "    broel.\n",
      "    bueren.\n",
      "    geisbach.\n",
      "    gemuend.\n",
      "    hagen-haspe.\n",
      "    herrntrop.\n",
      "    kornelimuenster.\n",
      "    lohmar.\n",
      "    meschede.\n",
      "    morsbach.\n",
      "    nespen.\n",
      "    niederschelden2.\n",
      "    oberagger.\n",
      "    opladen.\n",
      "    rebbelroth.\n",
      "    rueblinghausen.\n",
      "    stephansohl.\n",
      "    walkmuehle.\n",
      "    weidenau.\n",
      "    weidenau2.\n",
      "    weine.\n",
      "    welda.\n",
      "Processing short term rel values for mzb...\n",
      "  Norway:\n",
      "    S109.2.\n",
      "    S109.21.\n",
      "    S109.9.\n",
      "    S12.137.\n",
      "    S12.2.\n",
      "    S12.207.\n",
      "    S12.7.\n",
      "    S12.8.\n",
      "    S16.1.\n",
      "    S16.128.\n",
      "    S16.132.\n",
      "    S16.155.\n",
      "    S16.193.\n",
      "    S16.51.\n",
      "    S19.72.\n",
      "    S2.129.\n",
      "    S2.267.\n",
      "    S2.268.\n",
      "    S2.303.\n",
      "    S2.32.\n",
      "    S2.434.\n",
      "    S2.439.\n",
      "    S2.479.\n",
      "    S2.592.\n",
      "    S2.611.\n",
      "    S20.2.\n",
      "    S21.21.\n",
      "    S25.6.\n",
      "    S27.13.\n",
      "    S27.15.\n",
      "    S27.16.\n",
      "    S30.8.\n",
      "    S35.2.\n",
      "    S36.31.\n",
      "    S36.32.\n",
      "    S50.11.\n",
      "    S50.13.\n",
      "    S6.10.\n",
      "    S6.9.\n",
      "    S8.2.\n",
      "  Germany:\n",
      "    altenburg.\n",
      "    beddelhausen.\n",
      "    bredelar.\n",
      "    broel.\n",
      "    bueren.\n",
      "    geisbach.\n",
      "    gemuend.\n",
      "    hagen-haspe.\n",
      "    herrntrop.\n",
      "    kornelimuenster.\n",
      "    lohmar.\n",
      "    meschede.\n",
      "    morsbach.\n",
      "    nespen.\n",
      "    niederschelden2.\n",
      "    oberagger.\n",
      "    opladen.\n",
      "    rebbelroth.\n",
      "    rueblinghausen.\n",
      "    stephansohl.\n",
      "    walkmuehle.\n",
      "    weidenau.\n",
      "    weidenau2.\n",
      "    weine.\n",
      "    welda.\n",
      "Processing long term abs values for pb...\n",
      "  Norway:\n",
      "    S109.2.\n",
      "    S109.21.\n",
      "    S109.9.\n",
      "    S12.137.\n",
      "    S12.2.\n",
      "    S12.207.\n",
      "    S12.7.\n",
      "    S12.8.\n",
      "    S16.1.\n",
      "    S16.128.\n",
      "    S16.132.\n",
      "    S16.155.\n",
      "    S16.193.\n",
      "    S16.51.\n",
      "    S19.72.\n",
      "    S2.129.\n",
      "    S2.267.\n",
      "    S2.268.\n",
      "    S2.303.\n",
      "    S2.32.\n",
      "    S2.434.\n",
      "    S2.439.\n",
      "    S2.479.\n",
      "    S2.592.\n",
      "    S2.611.\n",
      "    S20.2.\n",
      "    S21.21.\n",
      "    S25.6.\n",
      "    S27.13.\n",
      "    S27.15.\n",
      "    S27.16.\n",
      "    S30.8.\n",
      "    S35.2.\n",
      "    S36.31.\n",
      "    S36.32.\n",
      "    S50.11.\n",
      "    S50.13.\n",
      "    S6.10.\n",
      "    S6.9.\n",
      "    S8.2.\n",
      "  Germany:\n",
      "    altenburg.\n",
      "    beddelhausen.\n",
      "    bredelar.\n",
      "    broel.\n",
      "    bueren.\n",
      "    geisbach.\n",
      "    gemuend.\n",
      "    hagen-haspe.\n",
      "    herrntrop.\n",
      "    kornelimuenster.\n",
      "    lohmar.\n",
      "    meschede.\n",
      "    morsbach.\n",
      "    nespen.\n",
      "    niederschelden2.\n",
      "    oberagger.\n",
      "    opladen.\n",
      "    rebbelroth.\n",
      "    rueblinghausen.\n",
      "    stephansohl.\n",
      "    walkmuehle.\n",
      "    weidenau.\n",
      "    weidenau2.\n",
      "    weine.\n",
      "    welda.\n",
      "Processing long term abs values for mzb...\n",
      "  Norway:\n",
      "    S109.2.\n",
      "    S109.21.\n",
      "    S109.9.\n",
      "    S12.137.\n",
      "    S12.2.\n",
      "    S12.207.\n",
      "    S12.7.\n",
      "    S12.8.\n",
      "    S16.1.\n",
      "    S16.128.\n",
      "    S16.132.\n",
      "    S16.155.\n",
      "    S16.193.\n",
      "    S16.51.\n",
      "    S19.72.\n",
      "    S2.129.\n",
      "    S2.267.\n",
      "    S2.268.\n",
      "    S2.303.\n",
      "    S2.32.\n",
      "    S2.434.\n",
      "    S2.439.\n",
      "    S2.479.\n",
      "    S2.592.\n",
      "    S2.611.\n",
      "    S20.2.\n",
      "    S21.21.\n",
      "    S25.6.\n",
      "    S27.13.\n",
      "    S27.15.\n",
      "    S27.16.\n",
      "    S30.8.\n",
      "    S35.2.\n",
      "    S36.31.\n",
      "    S36.32.\n",
      "    S50.11.\n",
      "    S50.13.\n",
      "    S6.10.\n",
      "    S6.9.\n",
      "    S8.2.\n",
      "  Germany:\n",
      "    altenburg.\n",
      "    beddelhausen.\n",
      "    bredelar.\n",
      "    broel.\n",
      "    bueren.\n",
      "    geisbach.\n",
      "    gemuend.\n",
      "    hagen-haspe.\n",
      "    herrntrop.\n",
      "    kornelimuenster.\n",
      "    lohmar.\n",
      "    meschede.\n",
      "    morsbach.\n",
      "    nespen.\n",
      "    niederschelden2.\n",
      "    oberagger.\n",
      "    opladen.\n",
      "    rebbelroth.\n",
      "    rueblinghausen.\n",
      "    stephansohl.\n",
      "    walkmuehle.\n",
      "    weidenau.\n",
      "    weidenau2.\n",
      "    weine.\n",
      "    welda.\n",
      "Processing long term rel values for pb...\n",
      "  Norway:\n",
      "    S109.2.\n",
      "    S109.21.\n",
      "    S109.9.\n",
      "    S12.137.\n",
      "    S12.2.\n",
      "    S12.207.\n",
      "    S12.7.\n",
      "    S12.8.\n",
      "    S16.1.\n",
      "    S16.128.\n",
      "    S16.132.\n",
      "    S16.155.\n",
      "    S16.193.\n",
      "    S16.51.\n",
      "    S19.72.\n",
      "    S2.129.\n",
      "    S2.267.\n",
      "    S2.268.\n",
      "    S2.303.\n",
      "    S2.32.\n",
      "    S2.434.\n",
      "    S2.439.\n",
      "    S2.479.\n",
      "    S2.592.\n",
      "    S2.611.\n",
      "    S20.2.\n",
      "    S21.21.\n",
      "    S25.6.\n",
      "    S27.13.\n",
      "    S27.15.\n",
      "    S27.16.\n",
      "    S30.8.\n",
      "    S35.2.\n",
      "    S36.31.\n",
      "    S36.32.\n",
      "    S50.11.\n",
      "    S50.13.\n",
      "    S6.10.\n",
      "    S6.9.\n",
      "    S8.2.\n",
      "  Germany:\n",
      "    altenburg.\n",
      "    beddelhausen.\n",
      "    bredelar.\n",
      "    broel.\n",
      "    bueren.\n",
      "    geisbach.\n",
      "    gemuend.\n",
      "    hagen-haspe.\n",
      "    herrntrop.\n",
      "    kornelimuenster.\n",
      "    lohmar.\n",
      "    meschede.\n",
      "    morsbach.\n",
      "    nespen.\n",
      "    niederschelden2.\n",
      "    oberagger.\n",
      "    opladen.\n",
      "    rebbelroth.\n",
      "    rueblinghausen.\n",
      "    stephansohl.\n",
      "    walkmuehle.\n",
      "    weidenau.\n",
      "    weidenau2.\n",
      "    weine.\n",
      "    welda.\n",
      "Processing long term rel values for mzb...\n",
      "  Norway:\n",
      "    S109.2.\n",
      "    S109.21.\n",
      "    S109.9.\n",
      "    S12.137.\n",
      "    S12.2.\n",
      "    S12.207.\n",
      "    S12.7.\n",
      "    S12.8.\n",
      "    S16.1.\n",
      "    S16.128.\n",
      "    S16.132.\n",
      "    S16.155.\n",
      "    S16.193.\n",
      "    S16.51.\n",
      "    S19.72.\n",
      "    S2.129.\n",
      "    S2.267.\n",
      "    S2.268.\n",
      "    S2.303.\n",
      "    S2.32.\n",
      "    S2.434.\n",
      "    S2.439.\n",
      "    S2.479.\n",
      "    S2.592.\n",
      "    S2.611.\n",
      "    S20.2.\n",
      "    S21.21.\n",
      "    S25.6.\n",
      "    S27.13.\n",
      "    S27.15.\n",
      "    S27.16.\n",
      "    S30.8.\n",
      "    S35.2.\n",
      "    S36.31.\n",
      "    S36.32.\n",
      "    S50.11.\n",
      "    S50.13.\n",
      "    S6.10.\n",
      "    S6.9.\n",
      "    S8.2.\n",
      "  Germany:\n",
      "    altenburg.\n",
      "    beddelhausen.\n",
      "    bredelar.\n",
      "    broel.\n",
      "    bueren.\n",
      "    geisbach.\n",
      "    gemuend.\n",
      "    hagen-haspe.\n",
      "    herrntrop.\n",
      "    kornelimuenster.\n",
      "    lohmar.\n",
      "    meschede.\n",
      "    morsbach.\n",
      "    nespen.\n",
      "    niederschelden2.\n",
      "    oberagger.\n",
      "    opladen.\n",
      "    rebbelroth.\n",
      "    rueblinghausen.\n",
      "    stephansohl.\n",
      "    walkmuehle.\n",
      "    weidenau.\n",
      "    weidenau2.\n",
      "    weine.\n",
      "    welda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Data\\64_Bit_WinPython\\python-2.7.10.amd64\\lib\\site-packages\\ipykernel\\__main__.py:17: FutureWarning: The pandas.rpy module is deprecated and will be removed in a future version. We refer to external packages like rpy2. \n",
      "See here for a guide on how to port your code to rpy2: http://pandas.pydata.org/pandas-docs/stable/r_interface.html\n"
     ]
    }
   ],
   "source": [
    "# Output file\n",
    "out_xlsx = r'\\\\niva-of5\\osl-userdata$\\JES\\Documents\\James_Work\\Staff\\Susi_S\\ECOREG\\IHA_Params\\iha_params.xlsx'\n",
    "writer = pd.ExcelWriter(out_xlsx)\n",
    "\n",
    "# Loop over periods, statistics and ecological indices\n",
    "for per in ['short', 'long']:\n",
    "    for stat in ['abs', 'rel']:\n",
    "        for eco in ['pb', 'mzb']:\n",
    "            # DF to store output\n",
    "            df_list = []\n",
    "\n",
    "            # Process Norwegain sites\n",
    "            print 'Processing %s term %s values for %s...' % (per, stat, eco)\n",
    "            print '  Norway:'\n",
    "\n",
    "            for col in nor_df.columns:\n",
    "                # Print progress\n",
    "                print '    %s.' % col\n",
    "\n",
    "                # Define long and short periods according to station\n",
    "                if per == 'short':\n",
    "                    yrs = 1\n",
    "                elif (per == 'long') and (col == 'S25.6'): # Only use 3 years for Homstølvatn\n",
    "                    yrs = 3\n",
    "                else: \n",
    "                    yrs = 5\n",
    "\n",
    "                # Get start and end dates\n",
    "                end = nor_sites[nor_sites['site']==col].iloc[0]['date']\n",
    "                st = end - pd.DateOffset(years=yrs)\n",
    "\n",
    "                # Get series and trunctae\n",
    "                df = nor_df[[col]].truncate(before=st, after=end)\n",
    "\n",
    "                # Fill no data\n",
    "                df.interpolate(method='linear', inplace=True)\n",
    "                \n",
    "                # Assert no missing values remain\n",
    "                assert df.isnull().sum(axis=0)[0] == 0, 'Dataframe has missing values'\n",
    "\n",
    "                # Calculate relative values if necessary\n",
    "                if stat == 'rel':\n",
    "                    # \"Normalise\" by dividing by the mean\n",
    "                    df = df / df.mean()\n",
    "\n",
    "                # Append results\n",
    "                df_list.append(process_iha(df))\n",
    "\n",
    "            # Process German sites\n",
    "            print '  Germany:'\n",
    "\n",
    "            for col in ger_df.columns:\n",
    "                # Print progress\n",
    "                print '    %s.' % col\n",
    "\n",
    "                # Decide whether to process this site\n",
    "                if ((eco == 'mzb') and (col in ger_sites['name'][ger_sites['use_mzb'].isnull()].values)):\n",
    "                    pass\n",
    "                else:\n",
    "                    # Get the site code\n",
    "                    site = ger_sites[ger_sites['name']==col].iloc[0]['site']\n",
    "                    \n",
    "                    # Define long and short periods\n",
    "                    if per == 'short':\n",
    "                        yrs = 1\n",
    "                    else: \n",
    "                        yrs = 5\n",
    "\n",
    "                    # Get start year and end year for this site\n",
    "                    end = ger_sites[ger_sites['name']==col].iloc[0][eco]\n",
    "                    st = end - pd.DateOffset(years=yrs)\n",
    "\n",
    "                    # Get series and trunctae at specified dates\n",
    "                    df = ger_df[[col]].truncate(before=st, after=end)\n",
    "\n",
    "                    # Rename with site code rather than site name\n",
    "                    df.columns = [site,]\n",
    "                    \n",
    "                    # Fill no data\n",
    "                    df.interpolate(method='linear', inplace=True)\n",
    "\n",
    "                    # Assert no missing values remain\n",
    "                    assert df.isnull().sum(axis=0).iloc[0] == 0, 'Dataframe has missing values'\n",
    "\n",
    "                    # Append results\n",
    "                    df_list.append(process_iha(df))\n",
    "\n",
    "            # Combine into final output\n",
    "            iha_params = pd.concat(df_list, axis=1)\n",
    "\n",
    "            # Get just the 'Cent_Est' columns\n",
    "            iha_df = iha_params.xs('Cent_Est', level=1, axis=1).reset_index()\n",
    "            iha_df.index = iha_df['Indicator']\n",
    "            del iha_df['Group'], iha_df['Indicator']\n",
    "\n",
    "            # Convert shape to samples x features\n",
    "            iha_df = iha_df.T\n",
    "\n",
    "            # Join in site names and reorder columns\n",
    "            iha_cols = list(iha_df.columns)\n",
    "            iha_df = pd.merge(iha_df, codes, how='left', left_index=True, right_index=True)\n",
    "            iha_df = iha_df[['name',]+iha_cols]\n",
    "            \n",
    "            # Write output (ignoring CoD stats. for now)\n",
    "            iha_df.to_excel(writer, '%s_term_%s_%s' % (per, stat, eco))\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
