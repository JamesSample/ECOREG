{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import imp\n",
    "import pymc3 as pm\n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "sn.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optionally suppress warnings in the final version of the notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECOREG full analysis (part 3: relationships)\n",
    "\n",
    "This notebook follows on from the work described [here](http://nbviewer.jupyter.org/github/JamesSample/ECOREG/blob/master/ecoreg_full_analysis_1.ipynb) and [here](http://nbviewer.jupyter.org/github/JamesSample/ECOREG/blob/master/ecoreg_full_analysis_2.ipynb). In the first notebook, PCA was used to identify a subset of potentially interesting parameters with reduced collinearity; in the second, potentially interesting patterns highlighted by the PCA were explored by testing for differences between regulated and unregulated sites. In this notebook, I want to explore relationships between the variables, following up on hypotheses developed in notebooks 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read basic datasets\n",
    "\n",
    "# Hydro indicators\n",
    "in_xls = r'C:\\Data\\James_Work\\Staff\\Susi_S\\ECOREG\\Stats_Input_Data\\hydro_indic.xlsx'\n",
    "hi_df = pd.read_excel(in_xls, sheetname='hydro_indic', index_col=0)\n",
    "hi_df = hi_df.query('(eco_dataset == \"pb\") and (time_per == 3)')\n",
    "\n",
    "# Site props\n",
    "in_xls = r'C:\\Data\\James_Work\\Staff\\Susi_S\\ECOREG\\Stats_Input_Data\\site_props.xlsx'\n",
    "site_df = pd.read_excel(in_xls, sheetname='site_props', index_col=0)\n",
    "\n",
    "# MZB\n",
    "in_xls = r'C:\\Data\\James_Work\\Staff\\Susi_S\\ECOREG\\Stats_Input_Data\\mzb_chem_ecol.xlsx'\n",
    "mzb_df = pd.read_excel(in_xls, sheetname='mzb_data', index_col=0)\n",
    "\n",
    "# PB\n",
    "in_xls = r'C:\\Data\\James_Work\\Staff\\Susi_S\\ECOREG\\Stats_Input_Data\\pb_chem_ecol.xlsx'\n",
    "pb_df = pd.read_excel(in_xls, sheetname='pb_data', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import custom functions\n",
    "func_path = r'C:\\Data\\James_Work\\Staff\\Susi_S\\ECOREG\\Python\\ECOREG\\ecoreg_code.py'\n",
    "\n",
    "ecoreg = imp.load_source('ecoreg_code', func_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Relationships to explore\n",
    "\n",
    "### 6.1. Germany\n",
    "\n",
    "Based on the results in the previous two notebooks, it seems reasonable to concentrate on the following reduced set of response and explanatory variables for Germany:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Norway\n",
    "\n",
    "#### 6.2.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['abund', 'n_taxa', 'n_genera', 'sessil', 'acti_filt_feed',\n",
    "        'swim_div', 'p50', 'cv', 'revs_per_yr', 'av_rise_rt', \n",
    "        'av_fall_rt', 'tn', 'toc', 'country', 'regulated']\n",
    "df = pd.concat([site_df, mzb_df, hi_df], axis=1)[cols]\n",
    "df = df.query('country == \"N\"')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = ['n_taxa', 'tn', 'toc', 'cond', 'mean', 'range', 'max12', \n",
    "        'revs_per_yr', 'days_to_p95', 'days_to_max', 'max10', \n",
    "        'cv', 'p50', 'country', 'regulated']\n",
    "df = pd.concat([site_df, mzb_df, hi_df], axis=1)[cols]\n",
    "df = df.query('country == \"N\"')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lists of explan and resp vars\n",
    "exp_vars = ['tn', 'toc', 'cond', 'mean', 'range', 'max12', 'revs_per_yr', \n",
    "            'days_to_p95', 'days_to_max', 'max10', 'cv']\n",
    "resp_var = 'n_taxa'\n",
    "\n",
    "res_df, fig = ecoreg.plot_lasso_path(df, resp_var, exp_vars)\n",
    "\n",
    "mpld3.display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lists of explan and resp vars\n",
    "exp_vars = ['tn', 'cv', 'toc', 'revs_per_yr', 'mean']\n",
    "resp_var = 'n_taxa'\n",
    "\n",
    "res_df, fig = ecoreg.plot_lasso_path(df, resp_var, exp_vars)\n",
    "\n",
    "mpld3.display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lists of explan and resp vars\n",
    "exp_vars = ['tn', 'toc', 'cond', 'mean', 'range', 'max12', 'revs_per_yr', \n",
    "            'days_to_p95', 'days_to_max', 'max10', 'cv']\n",
    "resp_var = 'n_taxa'\n",
    "\n",
    "params = best_lasso(df, resp_var, exp_vars, kcv=3, cv_path=True, hists=True)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod_str = 'n_taxa ~ tn'# + cv'\n",
    "\n",
    "# Regression. Pass alpha=0 for OLS. Larger alpha gives a bigger penalty on the\n",
    "# size of the parameter estimates\n",
    "model = smf.ols(mod_str, data=df).fit_regularized(alpha=0, l1_wt=0)\n",
    "\n",
    "print model.summary()\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "fig = sm.graphics.plot_partregress_grid(model, fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Lists of explan and resp vars\n",
    "exp_vars = ['tn', 'toc', 'cond', 'mean', 'range', 'max12', 'revs_per_yr', \n",
    "            'days_to_p95', 'days_to_max', 'max10', 'cv']\n",
    "resp_var = 'n_taxa'\n",
    "\n",
    "# Dict to store BIC values\n",
    "bics = {}\n",
    "\n",
    "# Loop over all combinations\n",
    "for k in range(1, len(exp_vars)+1):\n",
    "    for variables in itertools.combinations(exp_vars, k):\n",
    "        preds = df[list(variables)]\n",
    "        \n",
    "        # Add constant\n",
    "        preds = sm.add_constant(preds)\n",
    "        \n",
    "        # Compute OLS results\n",
    "        res = sm.OLS(df[[resp_var,]], preds).fit()\n",
    "        \n",
    "        # Add result to dict\n",
    "        bics[variables] = res.bic\n",
    "\n",
    "# Get the combination with lowest BIC\n",
    "best_vars = list(min(bics, key=bics.get))\n",
    "\n",
    "# Print regression results for these vars\n",
    "preds = df[list(best_vars)]\n",
    "\n",
    "# Add constant\n",
    "preds = sm.add_constant(preds)\n",
    "\n",
    "# Compute OLS results\n",
    "res = sm.OLS(df[[resp_var,]], preds).fit()\n",
    "\n",
    "print 'Regression results for the model with the lowest BIC:\\n'\n",
    "print res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Robust Bayesian regression\n",
    "var_map = {'x':'toc',\n",
    "           'y':'n_taxa'}\n",
    "\n",
    "res = ecoreg.robust_lin_reg(df, var_map, plot_trace=True,\n",
    "                            plot_vars=True, mcmc='slice', \n",
    "                            steps=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
